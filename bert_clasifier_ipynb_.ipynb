{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Necessary Libraries"
   ],
   "metadata": {
    "id": "_ojSZ5hvYnvV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from tensorflow import keras \n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "SlW7YHjGz0o5",
    "outputId": "1120051f-c792-4568-ac1f-f469bf4e4044"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading The Data"
   ],
   "metadata": {
    "id": "3JEJQ70-Ze4X"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_raw = pd.read_csv('train_6128.csv')\n",
    "train_raw.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                                               Text MLclass\n",
       "0        5860  1\\r\\ni SUPPLIES & SOLUTIONS FOR INDUSTRY\\r\\nww...  single\n",
       "1        6007  \\r\\nC. BEAN TRANSPORT, INC.\\r\\n(VAN DIVISION)\\...  single\n",
       "2        1192  support@almo.com Tuesday, June 10, 2014 1:46 P...  single\n",
       "3        6214  1\\r\\nMuller Martini 456 Wheeler Rd Hauppauge, ...  single\n",
       "4        4231  INVOICE\\r\\nAndrews\\r\\nAndrews Paperboard, Inc....  single"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>MLclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5860</td>\n",
       "      <td>1\\r\\ni SUPPLIES &amp; SOLUTIONS FOR INDUSTRY\\r\\nww...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6007</td>\n",
       "      <td>\\r\\nC. BEAN TRANSPORT, INC.\\r\\n(VAN DIVISION)\\...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1192</td>\n",
       "      <td>support@almo.com Tuesday, June 10, 2014 1:46 P...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6214</td>\n",
       "      <td>1\\r\\nMuller Martini 456 Wheeler Rd Hauppauge, ...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4231</td>\n",
       "      <td>INVOICE\\r\\nAndrews\\r\\nAndrews Paperboard, Inc....</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "82TK3tDYzpqm",
    "outputId": "af1cc890-7712-44ed-be0d-b30a10b4b081"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_raw.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6128, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "S6kyJH661det",
    "outputId": "6ab0745a-f50b-43fa-b0a8-ad44a9e6dffc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Data"
   ],
   "metadata": {
    "id": "-Hr1v_VoZqws"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select non null:"
   ],
   "metadata": {
    "id": "wbxSBv8m6XaR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_raw = train_raw[train_raw.Text.notnull()]\n",
    "train_raw.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6127, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wmb8-t51zx0n",
    "outputId": "5156b4fd-d78f-43e2-ca3a-37c0bc20e8b3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_raw.Text.apply(lambda x: len(x.split())).plot(kind='hist')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "pAMdnQBv1qlC",
    "outputId": "b0cad918-406f-484e-a922-695ce9c01ab3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_raw['len_txt'] =train_raw.Text.apply(lambda x: len(x.split()))\n",
    "train_raw.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Unnamed: 0      len_txt\n",
       "count  6127.000000  6127.000000\n",
       "mean   3843.316631   200.015668\n",
       "std    2201.616986   118.279703\n",
       "min       1.000000     1.000000\n",
       "25%    1957.500000   125.000000\n",
       "50%    3845.000000   181.000000\n",
       "75%    5744.000000   252.000000\n",
       "max    7659.000000  2317.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6127.000000</td>\n",
       "      <td>6127.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3843.316631</td>\n",
       "      <td>200.015668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2201.616986</td>\n",
       "      <td>118.279703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1957.500000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3845.000000</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5744.000000</td>\n",
       "      <td>252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7659.000000</td>\n",
       "      <td>2317.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "eGyH4kwB0TH6",
    "outputId": "c8117d31-a15b-49f4-d6e0-8e9b905a2c65"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_raw.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6127, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LqFgGC_TkvyA",
    "outputId": "db5dff6d-862a-45cf-a71c-957c81cb5888"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select only the row with number of words greater than 250:"
   ],
   "metadata": {
    "id": "SumN633drVVO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_raw = train_raw[train_raw.len_txt >249]\n",
    "train_raw.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1582, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "maZQzkqv0iFa",
    "outputId": "ceb3600d-cc69-478a-d5a9-b45ce797bd61"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Group similar products"
   ],
   "metadata": {
    "id": "beKGErd96q9p"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for l in np.unique(train_raw['MLclass']):\n",
    "  print(l)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "first\n",
      "intermediate\n",
      "last\n",
      "single\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "4jG9xKs1CJnh",
    "outputId": "57102e86-62ab-4dc0-d4fd-f48020ecf525"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_raw['MLclass'].value_counts().sort_values(ascending=False).plot(kind='bar')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "ISkKV5RX344m",
    "outputId": "225b6441-e028-4983-c10d-cd2a3f45cbc6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_raw=train_raw.rename(columns = {'Text':'text', 'MLclass':'label'})\n",
    "train_raw.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Unnamed: 0                                               text   label  \\\n",
       "5         1513  GRAINGER\\r\\n11\\r\\nPAGE 1 OF 1\\r\\n7200 NW 37TH ...  single   \n",
       "8         7645  ro to u >\\r\\n........ ?v. f {f. i. 0\\t,\\teea-i...   first   \n",
       "14        4012  Gordon\\r\\nFOOD SERVICE\\r\\nGordon Food Service ...  single   \n",
       "17        4094  PAGE 1\\r\\nGRAINGER\\r\\n11\\r\\n2775 S. 900 W.\\r\\n...  single   \n",
       "19        5230  INVOICE\\r\\nREMIT TO: 37302 Eagle Wav - Chicago...  single   \n",
       "\n",
       "    len_txt  \n",
       "5       286  \n",
       "8       261  \n",
       "14      408  \n",
       "17      278  \n",
       "19      290  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1513</td>\n",
       "      <td>GRAINGER\\r\\n11\\r\\nPAGE 1 OF 1\\r\\n7200 NW 37TH ...</td>\n",
       "      <td>single</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7645</td>\n",
       "      <td>ro to u &gt;\\r\\n........ ?v. f {f. i. 0\\t,\\teea-i...</td>\n",
       "      <td>first</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4012</td>\n",
       "      <td>Gordon\\r\\nFOOD SERVICE\\r\\nGordon Food Service ...</td>\n",
       "      <td>single</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4094</td>\n",
       "      <td>PAGE 1\\r\\nGRAINGER\\r\\n11\\r\\n2775 S. 900 W.\\r\\n...</td>\n",
       "      <td>single</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5230</td>\n",
       "      <td>INVOICE\\r\\nREMIT TO: 37302 Eagle Wav - Chicago...</td>\n",
       "      <td>single</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "CXWBl1Ao4FW4",
    "outputId": "46ba5d89-7497-4f0a-f89c-6f25f9cc85fa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
    "train_raw.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Unnamed: 0                                               text  label  \\\n",
       "5         1513  GRAINGER\\r\\n11\\r\\nPAGE 1 OF 1\\r\\n7200 NW 37TH ...      3   \n",
       "8         7645  ro to u >\\r\\n........ ?v. f {f. i. 0\\t,\\teea-i...      0   \n",
       "14        4012  Gordon\\r\\nFOOD SERVICE\\r\\nGordon Food Service ...      3   \n",
       "17        4094  PAGE 1\\r\\nGRAINGER\\r\\n11\\r\\n2775 S. 900 W.\\r\\n...      3   \n",
       "19        5230  INVOICE\\r\\nREMIT TO: 37302 Eagle Wav - Chicago...      3   \n",
       "\n",
       "    len_txt  \n",
       "5       286  \n",
       "8       261  \n",
       "14      408  \n",
       "17      278  \n",
       "19      290  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1513</td>\n",
       "      <td>GRAINGER\\r\\n11\\r\\nPAGE 1 OF 1\\r\\n7200 NW 37TH ...</td>\n",
       "      <td>3</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7645</td>\n",
       "      <td>ro to u &gt;\\r\\n........ ?v. f {f. i. 0\\t,\\teea-i...</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4012</td>\n",
       "      <td>Gordon\\r\\nFOOD SERVICE\\r\\nGordon Food Service ...</td>\n",
       "      <td>3</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4094</td>\n",
       "      <td>PAGE 1\\r\\nGRAINGER\\r\\n11\\r\\n2775 S. 900 W.\\r\\n...</td>\n",
       "      <td>3</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5230</td>\n",
       "      <td>INVOICE\\r\\nREMIT TO: 37302 Eagle Wav - Chicago...</td>\n",
       "      <td>3</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "JFckqSM_4Pvr",
    "outputId": "46f83ccc-0d07-406c-a5d7-783c4b308412"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "len(np.unique(train_raw['label']))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VvAEbfcK40vP",
    "outputId": "1eecd4ae-177d-4578-b3df-adb2f137451f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_raw = train_raw[[\"text\", \"label\"]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train_raw.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 text  label\n",
       "5   GRAINGER\\r\\n11\\r\\nPAGE 1 OF 1\\r\\n7200 NW 37TH ...      3\n",
       "8   ro to u >\\r\\n........ ?v. f {f. i. 0\\t,\\teea-i...      0\n",
       "14  Gordon\\r\\nFOOD SERVICE\\r\\nGordon Food Service ...      3\n",
       "17  PAGE 1\\r\\nGRAINGER\\r\\n11\\r\\n2775 S. 900 W.\\r\\n...      3\n",
       "19  INVOICE\\r\\nREMIT TO: 37302 Eagle Wav - Chicago...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRAINGER\\r\\n11\\r\\nPAGE 1 OF 1\\r\\n7200 NW 37TH ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ro to u &gt;\\r\\n........ ?v. f {f. i. 0\\t,\\teea-i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gordon\\r\\nFOOD SERVICE\\r\\nGordon Food Service ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PAGE 1\\r\\nGRAINGER\\r\\n11\\r\\n2775 S. 900 W.\\r\\n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>INVOICE\\r\\nREMIT TO: 37302 Eagle Wav - Chicago...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "train = train_raw.copy()"
   ],
   "outputs": [],
   "metadata": {
    "id": "vjTcB2IElYK-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "train = train.reindex(np.random.permutation(train.index))\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  label\n",
       "3377  ORIGINAL INVOICE\\r\\nD.U.N.S\\r\\n>\\r\\n>\\r\\nc_\\r\\...      3\n",
       "5218  {PRAXAIR\\r\\nPRAXAIR DISTRIBUTION INC 3607 SOUT...      3\n",
       "4045  ] REMIT PAYMENT TO:\\r\\nCDW Direct\\r\\nPO Box 75...      3\n",
       "3222  lYtlLBf\\r\\nYELLOW TRANSPORTATION, INC. (YFSY) ...      3\n",
       "5474  Account Statement\\r\\nAudi\\r\\nFinancial Service...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>ORIGINAL INVOICE\\r\\nD.U.N.S\\r\\n&gt;\\r\\n&gt;\\r\\nc_\\r\\...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>{PRAXAIR\\r\\nPRAXAIR DISTRIBUTION INC 3607 SOUT...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>] REMIT PAYMENT TO:\\r\\nCDW Direct\\r\\nPO Box 75...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>lYtlLBf\\r\\nYELLOW TRANSPORTATION, INC. (YFSY) ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>Account Statement\\r\\nAudi\\r\\nFinancial Service...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_KSdpULo4vBM",
    "outputId": "fbd5b957-68d9-49fd-dc57-e485fa852c53"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the text columns"
   ],
   "metadata": {
    "id": "CJaaGqEC61Tw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import re\n",
    "def clean_txt(text):\n",
    "  text = re.sub(\"'\", \"\",text)\n",
    "  text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
    "  return text"
   ],
   "outputs": [],
   "metadata": {
    "id": "lFLkBvrnyKnt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "train['text']  = train.text.apply(clean_txt)\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  label\n",
       "3377  ORIGINAL INVOICE D U N S c_ MOHAWK CARPET MOHA...      3\n",
       "5218   PRAXAIR PRAXAIR DISTRIBUTION INC 3607 SOUTH M...      3\n",
       "4045   REMIT PAYMENT TO CDW Direct PO Box 75723 Chic...      3\n",
       "3222  lYtlLBf YELLOW TRANSPORTATION INC YFSY P 0 BOX...      3\n",
       "5474  Account Statement Audi Financial Services Summ...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>ORIGINAL INVOICE D U N S c_ MOHAWK CARPET MOHA...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>PRAXAIR PRAXAIR DISTRIBUTION INC 3607 SOUTH M...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>REMIT PAYMENT TO CDW Direct PO Box 75723 Chic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>lYtlLBf YELLOW TRANSPORTATION INC YFSY P 0 BOX...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>Account Statement Audi Financial Services Summ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "C4yHuGEayROw",
    "outputId": "000869c2-f3eb-46c1-8aec-cb54a868d372"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=35)\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   text  label\n",
       "3026  CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...      3\n",
       "5691  Wichita Kansas Topeka Kansas Overland Park Kan...      0\n",
       "4386  NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Sui...      0\n",
       "107   Invoice 943794 THE PRODUCE CONNECTION INC 2200...      3\n",
       "1023  1 YELLOW TRANSPORTATION INC YFSY YELLOW P 0 BO...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>Wichita Kansas Topeka Kansas Overland Park Kan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Sui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Invoice 943794 THE PRODUCE CONNECTION INC 2200...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1 YELLOW TRANSPORTATION INC YFSY YELLOW P 0 BO...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "S3EJew8g5cUK",
    "outputId": "5b0fe85f-23df-46ad-f705-776ad8e4d971"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "train.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...      3\n",
       "1  Wichita Kansas Topeka Kansas Overland Park Kan...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wichita Kansas Topeka Kansas Overland Park Kan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "2Cr7Ch3_5rnH",
    "outputId": "288d77ec-56c6-4fb5-b780-4216cf1c9f9b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "val.reset_index(drop=True, inplace=True)\n",
    "val.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  TEL 707 545 4540 FAX 707 545 5902 800 998 9070...      2\n",
       "1   Invoice McMASTER CARR 630 600 3600 630 834 94...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEL 707 545 4540 FAX 707 545 5902 800 998 9070...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Invoice McMASTER CARR 630 600 3600 630 834 94...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "6-1O5J9G54hV",
    "outputId": "dcc34ce3-2aa4-4c2b-eb27-d23bf4196f6d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "val.shape, train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((317, 2), (1265, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ziIsgHqrz0n6",
    "outputId": "7020b652-4989-41b1-9e32-c83666c6f9ac"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#Installing BERT module\n",
    "!pip install bert-tensorflow"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bert-tensorflow in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: six in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from bert-tensorflow) (1.16.0)\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "TGq2lzLG59SC",
    "outputId": "776bf6cb-74ba-40eb-c26a-247b684b574a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#Importing BERT modules\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "zTcMyKKl6DdA",
    "outputId": "fc31a0bb-4c45-4b7c-8dc9-752261c06f51"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting The Output Directory for BERT"
   ],
   "metadata": {
    "id": "ej8QOozZbEva"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Set the output directory for saving model file\n",
    "OUTPUT_DIR = './bert_news_category'\n",
    "\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "#tf.io.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "***** Model output directory: ./bert_news_category *****\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NNPhIMrr6ra9",
    "outputId": "ffc63c79-3bea-481d-8263-55f3e65decdb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "print(\"Training Set Shape :\", train.shape)\n",
    "print(\"Validation Set Shape :\", val.shape)\n",
    "# print(\"Test Set Shape :\", test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Set Shape : (1265, 2)\n",
      "Validation Set Shape : (317, 2)\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "0YGONt0p60Ay",
    "outputId": "5b986fab-16ed-4613-d2c9-554765ed86bd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "# The list containing all the classes (train['SECTION'].unique())\n",
    "label_list = [x for x in np.unique(train.label)]\n",
    "label_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "s6NYKx4P7N66",
    "outputId": "e7d7aa06-98d7-4d6f-d164-93b721c872e2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting the Data into smaller chunks"
   ],
   "metadata": {
    "id": "oOSEd24bbiUq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ],
   "outputs": [],
   "metadata": {
    "id": "ausf5AlOkPCH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "train['text_split'] = train[DATA_COLUMN].apply(get_split)\n",
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label  \\\n",
       "0  CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...      3   \n",
       "1  Wichita Kansas Topeka Kansas Overland Park Kan...      0   \n",
       "2  NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Sui...      0   \n",
       "3  Invoice 943794 THE PRODUCE CONNECTION INC 2200...      3   \n",
       "4  1 YELLOW TRANSPORTATION INC YFSY YELLOW P 0 BO...      3   \n",
       "\n",
       "                                          text_split  \n",
       "0  [CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRA...  \n",
       "1  [Wichita Kansas Topeka Kansas Overland Park Ka...  \n",
       "2  [NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Su...  \n",
       "3  [Invoice 943794 THE PRODUCE CONNECTION INC 220...  \n",
       "4  [1 YELLOW TRANSPORTATION INC YFSY YELLOW P 0 B...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...</td>\n",
       "      <td>3</td>\n",
       "      <td>[CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wichita Kansas Topeka Kansas Overland Park Kan...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Wichita Kansas Topeka Kansas Overland Park Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Sui...</td>\n",
       "      <td>0</td>\n",
       "      <td>[NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Invoice 943794 THE PRODUCE CONNECTION INC 2200...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Invoice 943794 THE PRODUCE CONNECTION INC 220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 YELLOW TRANSPORTATION INC YFSY YELLOW P 0 BO...</td>\n",
       "      <td>3</td>\n",
       "      <td>[1 YELLOW TRANSPORTATION INC YFSY YELLOW P 0 B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "E-u6mDkbLpTY",
    "outputId": "972100f3-569c-4a27-a24c-3fb2728d3581"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "val['text_split'] = val[DATA_COLUMN].apply(get_split)\n",
    "val.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label  \\\n",
       "0  TEL 707 545 4540 FAX 707 545 5902 800 998 9070...      2   \n",
       "1   Invoice McMASTER CARR 630 600 3600 630 834 94...      0   \n",
       "\n",
       "                                          text_split  \n",
       "0  [TEL 707 545 4540 FAX 707 545 5902 800 998 907...  \n",
       "1  [Invoice McMASTER CARR 630 600 3600 630 834 94...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEL 707 545 4540 FAX 707 545 5902 800 998 9070...</td>\n",
       "      <td>2</td>\n",
       "      <td>[TEL 707 545 4540 FAX 707 545 5902 800 998 907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Invoice McMASTER CARR 630 600 3600 630 834 94...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Invoice McMASTER CARR 630 600 3600 630 834 94...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "-zrlehCFUplB",
    "outputId": "7bd7c47a-adae-418a-c50e-29b2deb3c7d6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "train_l = []\n",
    "label_l = []\n",
    "index_l =[]\n",
    "for idx,row in train.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    train_l.append(l)\n",
    "    label_l.append(row['label'])\n",
    "    index_l.append(idx)\n",
    "len(train_l), len(label_l), len(index_l)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2578, 2578, 2578)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5_zMerj1VGaM",
    "outputId": "cc839f6a-8be6-40a9-aaa9-29752d8d5fff"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    val_l.append(l)\n",
    "    val_label_l.append(row['label'])\n",
    "    val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(634, 634, 634)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rBrXEaxHVNG4",
    "outputId": "de4dbc34-1fde-4233-a902-ab522cfc9520"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final dataset for training:"
   ],
   "metadata": {
    "id": "Hu5Sx8Rm0bAj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
    "train_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...      3\n",
       "1  NQI SEE NOTES ITEMS 154634 AND 154636 BOOTHS O...      3\n",
       "2  Wichita Kansas Topeka Kansas Overland Park Kan...      0\n",
       "3  19 Review settlement correspondence and attach...      0\n",
       "4  NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Sui...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRAN...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NQI SEE NOTES ITEMS 154634 AND 154636 BOOTHS O...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wichita Kansas Topeka Kansas Overland Park Kan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19 Review settlement correspondence and attach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NETSUITE OMSTSUM NDUMirS 2955 Campus Drive Sui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "mojRk8kWVVB4",
    "outputId": "95c4ea0f-7800-47b0-fa8a-9005671da2a0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  TEL 707 545 4540 FAX 707 545 5902 800 998 9070...      2\n",
       "1  3 43 31 1 1 I cs 18 ROLL COMPACT TISSUE CORELE...      2\n",
       "2  Invoice McMASTER CARR 630 600 3600 630 834 942...      0\n",
       "3  2 70 Each 13 50 3 4429K163 Low Pressure Brass ...      0\n",
       "4  Glasgow Audi Unit 1 Sentinel Court Hi Kington ...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEL 707 545 4540 FAX 707 545 5902 800 998 9070...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 43 31 1 1 I cs 18 ROLL COMPACT TISSUE CORELE...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Invoice McMASTER CARR 630 600 3600 630 834 942...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 70 Each 13 50 3 4429K163 Low Pressure Brass ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Glasgow Audi Unit 1 Sentinel Court Hi Kington ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "k_I-ZbSKVmrZ",
    "outputId": "ab55b3b8-5524-4cb3-bb23-a0a10c3a2bf0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT: Data Preprocessing "
   ],
   "metadata": {
    "id": "og08g7DScPtK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Process the data for BERT"
   ],
   "metadata": {
    "id": "2PWVomvm7TV5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ],
   "outputs": [],
   "metadata": {
    "id": "e-_zLSnh7evE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "train_InputExamples"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       <bert.run_classifier.InputExample object at 0x...\n",
       "1       <bert.run_classifier.InputExample object at 0x...\n",
       "2       <bert.run_classifier.InputExample object at 0x...\n",
       "3       <bert.run_classifier.InputExample object at 0x...\n",
       "4       <bert.run_classifier.InputExample object at 0x...\n",
       "                              ...                        \n",
       "2573    <bert.run_classifier.InputExample object at 0x...\n",
       "2574    <bert.run_classifier.InputExample object at 0x...\n",
       "2575    <bert.run_classifier.InputExample object at 0x...\n",
       "2576    <bert.run_classifier.InputExample object at 0x...\n",
       "2577    <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 2578, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "UOq7ETNe7zGJ",
    "outputId": "0c86519a-5376-4b21-be65-9c12f99afb6f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
    "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
    "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Row 0 - guid of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - text_a of training set :  CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRANSPORTATION SERVICES INC DUNS 10 155 1257 FED TAX ID 94 2904084 INVOICE 781 456922 CUSTOMER SERVICE PHONE 1 800 755 2728 FAX 817 514 3700 CORRESPONDENCE OVERNIGHT MAIL PO BOX 982020 5555 RUFE SNOW DR SUITE 5515 N RICHLAND HILLS TX 76182 N RICHLAND HILLS TX 76180 VISIT US AT www con wav com FOR A COPY OF THE BILL OF LADING OR PROOF OF DELIVERY H30 000202 030000 COOPER LIGHTING ATTN TRAFFIC DEPT 1121 HIGHWAY 74 S PEACHTREE CITS GA 30269 3019 B I L l T O SHIPPER CONSIGNEE CUSTOMER NUMBERS SHIPMENT DATE HARTWIG EXHIBITIONS COOPER LIGHTING BOOTH 649 SNS5131 FOR COOPER BOOTH 649 XFREEMAN DECOR 16325 W RYERSON RD 1616 WASHINGTON ST 03 25 05 NEW BERLIN WI 53151 3629 BRAINTREE MA 02184 PCS DESCRIPTION OF ARTICLES AND MARKS WEIGHT lbs RATE CHARGES 4 PCS E XHTBITIGN MATER IALS NQI SEE NOTES ITEMS 154634 AND 154636 BOOTHS OR STALL S IN BOXES CRATES OR TRUNKS SEE NOTE 154640 LOOSE WHEN SHIPMENT OVER 16 000 LB OR MORE 154630 CLASS 125 CON WAY DISCOUNT SAVES YOU FSC FUEL SURCHARGE 13 30 4 TOTAL 2180 2180 116 18 2532 72 1266\n",
      "\n",
      "__________\n",
      "Row 0 - text_b of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - label of training set :  3\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "d0E8U0OQ8VW6",
    "outputId": "0934f3f9-f7ae-44dc-fbef-4e038c8bb99a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT: Loading the pre-trained model"
   ],
   "metadata": {
    "id": "SoIt5AHadACM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "W4PZ8ogj8ae2",
    "outputId": "26a10fed-e770-41a2-e716-11d5cc7dc2ef"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(tokenizer.vocab.keys())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qS_ybJmv8lye",
    "outputId": "2c48b73b-eacc-4073-defc-934eaf83a24f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnparsedFlagAccessError",
     "evalue": "Trying to access flag --preserve_unused_tokens before flags were parsed.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-d5fd91c1d54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Here is what the tokenised sample of the first training set observation looks like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_InputExamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlower\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \"\"\"\n\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m       \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mpreserve_token\u001b[0;34m(token, vocab)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# get too much noise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnparsedFlagAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --preserve_unused_tokens before flags were parsed."
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "O6OqoZjv8r27",
    "outputId": "bad53d19-4e97-47cb-ad7c-3781ebb5e303"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MAX_SEQ_LENGTH = 200"
   ],
   "outputs": [],
   "metadata": {
    "id": "q87k_orF8vpz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2578\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2578\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnparsedFlagAccessError",
     "evalue": "Trying to access flag --preserve_unused_tokens before flags were parsed.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-d62457376f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert our train and validation features to InputFeatures that BERT understands.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_InputExamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_InputExamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/run_classifier.py\u001b[0m in \u001b[0;36mconvert_examples_to_features\u001b[0;34m(examples, label_list, max_seq_length, tokenizer)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/run_classifier.py\u001b[0m in \u001b[0;36mconvert_single_example\u001b[0;34m(ex_index, example, label_list, max_seq_length, tokenizer)\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0mtokens_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mtokens_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtokens_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlower\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \"\"\"\n\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m       \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mpreserve_token\u001b[0;34m(token, vocab)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# get too much noise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnparsedFlagAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --preserve_unused_tokens before flags were parsed."
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "G_LBy-yy-GSU",
    "outputId": "a1c02dff-0cd3-4ef8-c013-ced8dd6b484f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! pip install bert-tensorflow==1.0.1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting bert-tensorflow==1.0.1\n",
      "  Downloading bert_tensorflow-1.0.1-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     || 67 kB 2.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /home/komleva/anaconda3/envs/torchtext/lib/python3.7/site-packages (from bert-tensorflow==1.0.1) (1.16.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "  Attempting uninstall: bert-tensorflow\n",
      "    Found existing installation: bert-tensorflow 1.0.4\n",
      "    Uninstalling bert-tensorflow-1.0.4:\n",
      "      Successfully uninstalled bert-tensorflow-1.0.4\n",
      "Successfully installed bert-tensorflow-1.0.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Example on first observation in the training set\n",
    "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"-\"*30)\n",
    "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
    "print(\"-\"*30)\n",
    "print(\"Input IDs : \", train_features[0].input_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"Input Masks : \", train_features[0].input_mask)\n",
    "print(\"-\"*30)\n",
    "print(\"Segment IDs : \", train_features[0].segment_ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence :  CCM COniUftV CEHTRRL EXPRESS cwce CON WAY TRANSPORTATION SERVICES INC DUNS 10 155 1257 FED TAX ID 94 2904084 INVOICE 781 456922 CUSTOMER SERVICE PHONE 1 800 755 2728 FAX 817 514 3700 CORRESPONDENCE OVERNIGHT MAIL PO BOX 982020 5555 RUFE SNOW DR SUITE 5515 N RICHLAND HILLS TX 76182 N RICHLAND HILLS TX 76180 VISIT US AT www con wav com FOR A COPY OF THE BILL OF LADING OR PROOF OF DELIVERY H30 000202 030000 COOPER LIGHTING ATTN TRAFFIC DEPT 1121 HIGHWAY 74 S PEACHTREE CITS GA 30269 3019 B I L l T O SHIPPER CONSIGNEE CUSTOMER NUMBERS SHIPMENT DATE HARTWIG EXHIBITIONS COOPER LIGHTING BOOTH 649 SNS5131 FOR COOPER BOOTH 649 XFREEMAN DECOR 16325 W RYERSON RD 1616 WASHINGTON ST 03 25 05 NEW BERLIN WI 53151 3629 BRAINTREE MA 02184 PCS DESCRIPTION OF ARTICLES AND MARKS WEIGHT lbs RATE CHARGES 4 PCS E XHTBITIGN MATER IALS NQI SEE NOTES ITEMS 154634 AND 154636 BOOTHS OR STALL S IN BOXES CRATES OR TRUNKS SEE NOTE 154640 LOOSE WHEN SHIPMENT OVER 16 000 LB OR MORE 154630 CLASS 125 CON WAY DISCOUNT SAVES YOU FSC FUEL SURCHARGE 13 30 4 TOTAL 2180 2180 116 18 2532 72 1266\n",
      "------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnparsedFlagAccessError",
     "evalue": "Trying to access flag --preserve_unused_tokens before flags were parsed.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-6c38860b7291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sentence : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_InputExamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tokens : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_InputExamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input IDs : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mlower\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \"\"\"\n\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m       \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/bert/tokenization.py\u001b[0m in \u001b[0;36mpreserve_token\u001b[0;34m(token, vocab)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torchtext/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# get too much noise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnparsedFlagAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --preserve_unused_tokens before flags were parsed."
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "OLkn7RQ8_CV1",
    "outputId": "6de0cd1c-24c1-4cf1-beca-3e02941a8c82"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT: Creating A Multi-Class Classifier Model"
   ],
   "metadata": {
    "id": "piypsrPudMFf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  # with tf.Session() as sess:\n",
    "  output_layer1 = bert_outputs[\"pooled_output\"]\n",
    "  # output_layer1 = 999\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ],
   "outputs": [],
   "metadata": {
    "id": "TBxxy9s7GCW4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg,\n",
    "            }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs, output_layer) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'pooled_output': output_layer\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ],
   "outputs": [],
   "metadata": {
    "id": "rPRB5i1HG8JO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-b14eb549c849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Compute train and warmup steps from batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnum_train_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNUM_TRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_steps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWARMUP_PROPORTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "metadata": {
    "id": "fNrvabUFHC79"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_train_steps, len(label_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1979, 10)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 55
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xo70COnsHIWE",
    "outputId": "febad872-9d36-443b-b7ed-9202903facae"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Initializing the model and the estimator\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1fc8615630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1fc8615630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "zHlZKcq7HMzE",
    "outputId": "9c5ee0bf-d111-48f2-be4d-c01362521b6e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ],
   "outputs": [],
   "metadata": {
    "id": "05KBWhqeHUIF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT: Fine Tuning Training & Evaluating"
   ],
   "metadata": {
    "id": "Lm0AubBnhEst"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Training the model\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Beginning Training!\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-52-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From <ipython-input-52-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 2.4308736, step = 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 2.4308736, step = 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.73687\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.73687\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.9394433, step = 100 (57.578 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.9394433, step = 100 (57.578 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46178\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46178\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.5528544, step = 200 (40.620 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.5528544, step = 200 (40.620 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 300 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.17765\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.17765\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.71076536, step = 300 (45.921 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.71076536, step = 300 (45.921 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46341\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46341\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.96843326, step = 400 (40.594 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.96843326, step = 400 (40.594 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46412\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46412\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.6834893, step = 500 (40.582 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.6834893, step = 500 (40.582 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.18593\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.18593\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.57014453, step = 600 (45.747 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.57014453, step = 600 (45.747 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46392\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46392\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.18577647, step = 700 (40.586 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.18577647, step = 700 (40.586 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46287\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46287\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.44487035, step = 800 (40.603 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.44487035, step = 800 (40.603 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.17444\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.17444\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.91815966, step = 900 (45.989 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.91815966, step = 900 (45.989 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46392\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46392\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.96589124, step = 1000 (40.585 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.96589124, step = 1000 (40.585 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.464\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.464\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.52840304, step = 1100 (40.585 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.52840304, step = 1100 (40.585 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1200 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1200 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.17033\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.17033\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.53256005, step = 1200 (46.075 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.53256005, step = 1200 (46.075 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4627\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.4627\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.21745712, step = 1300 (40.606 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.21745712, step = 1300 (40.606 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46223\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46223\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.781665, step = 1400 (40.613 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.781665, step = 1400 (40.613 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.16825\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.16825\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.3196971, step = 1500 (46.120 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.3196971, step = 1500 (46.120 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46084\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46084\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.28183633, step = 1600 (40.637 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.28183633, step = 1600 (40.637 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46311\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46311\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.50631773, step = 1700 (40.598 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.50631773, step = 1700 (40.598 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1800 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1800 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.16985\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.16985\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.5347062, step = 1800 (46.086 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.5347062, step = 1800 (46.086 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46108\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.46108\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:loss = 0.54360807, step = 1900 (40.633 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:loss = 0.54360807, step = 1900 (40.633 sec)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1979 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1979 into /bert_news_category/model.ckpt.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.2288338.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.2288338.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training took time  0:15:36.286117\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JUhCik-iHj9o",
    "outputId": "6a44d761-e385-415f-bdc6-343c038adf67"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy for the fine tuned BERT model"
   ],
   "metadata": {
    "id": "b-EFK3DS0qkm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.8582935,\n",
       " 'false_negatives': 116.0,\n",
       " 'false_positives': 176.0,\n",
       " 'global_step': 1979,\n",
       " 'loss': 0.4725039,\n",
       " 'true_negatives': 693.0,\n",
       " 'true_positives': 6961.0}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 78
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "HSQxiqDPHrJy",
    "outputId": "c9705bcc-c7c3-41fa-99e2-0f6e8f446160"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! pip install https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.8.0-py3-none-any.whl\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow==1.8.0\n",
      "  Downloading https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.8.0-py3-none-any.whl (46.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorflow==1.8.0) (1.21.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorflow==1.8.0) (1.15.0)\n",
      "Collecting tensorboard<1.9.0,>=1.8.0\n",
      "  Downloading tensorboard-1.8.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorflow==1.8.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorflow==1.8.0) (3.17.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/komleva/.local/lib/python3.8/site-packages (from tensorflow==1.8.0) (1.39.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorflow==1.8.0) (0.36.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorflow==1.8.0) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/komleva/.local/lib/python3.8/site-packages (from tensorflow==1.8.0) (0.13.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorflow==1.8.0) (0.4.0)\n",
      "Collecting html5lib==0.9999999\n",
      "  Using cached html5lib-0.9999999.tar.gz (889 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /home/komleva/anaconda3/lib/python3.8/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.3.4)\n",
      "Collecting bleach==1.5.0\n",
      "  Using cached bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/komleva/.local/lib/python3.8/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (2.0.1)\n",
      "Building wheels for collected packages: html5lib\n",
      "  Building wheel for html5lib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html5lib: filename=html5lib-0.9999999-py3-none-any.whl size=107234 sha256=1d594446e4626996adf9d409ced4a83dd759b3f297a233b9d50bb6e3d4c05898\n",
      "  Stored in directory: /home/komleva/.cache/pip/wheels/dc/75/d2/3812ab8ba1fff9d3a0ed5bfc472174c9312055b1b80a94834b\n",
      "Successfully built html5lib\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: html5lib, bleach, tensorboard, tensorflow\n",
      "  Attempting uninstall: html5lib\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: html5lib 1.1\n",
      "    Uninstalling html5lib-1.1:\n",
      "      Successfully uninstalled html5lib-1.1\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 4.0.0\n",
      "    Uninstalling bleach-4.0.0:\n",
      "      Successfully uninstalled bleach-4.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: tensorflow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tensorflow 2.8.0\n",
      "    Uninstalling tensorflow-2.8.0:\n",
      "      Successfully uninstalled tensorflow-2.8.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.2.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 4.2.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "spyder 4.2.5 requires jedi==0.17.2, but you have jedi 0.18.0 which is incompatible.\n",
      "spyder 4.2.5 requires parso==0.7.0, but you have parso 0.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bleach-3.3.0 html5lib-0.9999999 tensorboard-1.9.0 tensorflow-1.8.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/komleva/anaconda3/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT: Get The Vector Transformations from the Fine Tuned BERT"
   ],
   "metadata": {
    "id": "ubX4mo7ahbZI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# A method to get predictions\n",
    "def getPrediction(in_sentences, type_output = \"features\"):\n",
    "  #A list to map the actual labels to the predictions\n",
    "  labels = np.unique(train['label'])\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  if type_output == \"features\":\n",
    "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
    "  else:\n",
    "    return ([(sentence, prediction['probabilities'],\n",
    "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "7B114QMlVwMm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "MAX_SEQ_LENGTH"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 61
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WKpDMg-nV-yZ",
    "outputId": "af7b21e9-a87c-4de6-8168-6109991f4154"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_df.shape, val_df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((31679, 2), (7946, 2))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 62
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "EjRdLdqj-mpo",
    "outputId": "4f388f8d-e19b-42fa-fae2-74ce196c37ef"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now extracting the representations:"
   ],
   "metadata": {
    "id": "m4Q7Ih3nmNXh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "tr_emb = np.apply_along_axis(getPrediction, 0,np.array(train_df[DATA_COLUMN]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2min 35s, sys: 10.9 s, total: 2min 46s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "2z3hwrsaWECM",
    "outputId": "77174d69-c6ce-496d-d0c0-de79357db931"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "val_emb = np.apply_along_axis(getPrediction, 0,np.array(val_df[DATA_COLUMN]))\n",
    "val_emb.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 43.4 s, sys: 2.76 s, total: 46.2 s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "bw6nDeP2WR_u",
    "outputId": "fa1031d3-00f3-443d-ff63-60234d0c9375"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val_emb.shape, tr_emb.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((7946, 768), (31679, 768))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 66
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "BQbVWlptWUGE",
    "outputId": "1eca64c4-d696-4f8b-e154-e2d4bb8f1b2b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and make the dataset for train and val:"
   ],
   "metadata": {
    "id": "AbIDKTbw8lOt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "train_x = {}\n",
    "for l, emb in zip(index_l, tr_emb):\n",
    "  if l in train_x.keys():\n",
    "    train_x[l]  =np.vstack([train_x[l], emb])\n",
    "  else:\n",
    "    train_x[l] = [emb]\n",
    "\n",
    "len(train_x.keys())\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13713"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 67
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4bBZiJG6hEdU",
    "outputId": "24cdb344-81c4-4ebc-8967-cc8c746fa40c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_l_final = []\n",
    "label_l_final = []\n",
    "for k in train_x.keys():\n",
    "  train_l_final.append(train_x[k])\n",
    "  label_l_final.append(train.loc[k]['label'])\n",
    "\n",
    "df_train = pd.DataFrame({'emb': train_l_final, 'label': label_l_final, })\n",
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[0.848892, 0.05472551, -0.85581946, 0.4909455...      3\n",
       "1  [[0.4019187, 0.30476514, 0.034283057, -0.10456...      4\n",
       "2  [[0.9221226, -0.48432896, -0.9658792, 0.905419...      0\n",
       "3  [[-0.34883273, 0.5719657, -0.65025216, 0.69365...      3\n",
       "4  [[0.8565562, -0.18846692, -0.98491526, 0.75137...      2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.848892, 0.05472551, -0.85581946, 0.4909455...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.4019187, 0.30476514, 0.034283057, -0.10456...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.9221226, -0.48432896, -0.9658792, 0.905419...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.34883273, 0.5719657, -0.65025216, 0.69365...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.8565562, -0.18846692, -0.98491526, 0.75137...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 68
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Oq2tpvrUkyoa",
    "outputId": "f04c8fd6-c478-4cb3-a6d9-a3853a2b841c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "val_x = {}\n",
    "\n",
    "for l, emb in zip(val_index_l, val_emb):\n",
    "  if l in val_x.keys():\n",
    "    val_x[l]  =np.vstack([val_x[l], emb])\n",
    "  else:\n",
    "    val_x[l] = [emb]\n",
    "\n",
    "\n",
    "val_l_final = []\n",
    "vlabel_l_final = []\n",
    "for k in val_x.keys():\n",
    "  val_l_final.append(val_x[k])\n",
    "  vlabel_l_final.append(val.loc[k]['label'])\n",
    "\n",
    "df_val = pd.DataFrame({'emb': val_l_final, 'label': vlabel_l_final})\n",
    "df_val.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[0.7906871, -0.3191274, -0.82637614, 0.760878...      0\n",
       "1  [[-0.18997923, 0.5434573, -0.8482759, 0.609339...      3\n",
       "2  [[-0.2863525, 0.47603318, -0.84779084, 0.70149...      3\n",
       "3  [[-0.55615234, 0.6234803, -0.7726333, -0.04120...      3\n",
       "4  [[0.24671736, 0.24032024, 0.47350714, -0.00336...      2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.7906871, -0.3191274, -0.82637614, 0.760878...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.18997923, 0.5434573, -0.8482759, 0.609339...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.2863525, 0.47603318, -0.84779084, 0.70149...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.55615234, 0.6234803, -0.7726333, -0.04120...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.24671736, 0.24032024, 0.47350714, -0.00336...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 69
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "cnjcaZHqk6rf",
    "outputId": "b66be414-0f35-484f-a3e7-5b5b513d3e67"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_val, df_test = train_test_split(df_val, test_size=0.4, random_state=35)"
   ],
   "outputs": [],
   "metadata": {
    "id": "VMDe3KvcIM5q"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM: Creating the Final Model"
   ],
   "metadata": {
    "id": "rzIznwgQiD6x"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras import layers\n",
    "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
    "\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.LSTM(100,)(l_mask)\n",
    "out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
    "# And we add a softmax classifier on top\n",
    "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
    "# At model instantiation, we specify the input and the output:\n",
    "model = Model(text_input, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               347600    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 350,940\n",
      "Trainable params: 350,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "260A5YvElD2D",
    "outputId": "f57ea208-93e2-460f-c40f-eff2cddf84a9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((13713, 2), (2057, 2), (1372, 2))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 80
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_SR7cUPRlvNg",
    "outputId": "da689c92-5825-4297-9448-051def60e82b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The generator functions:"
   ],
   "metadata": {
    "id": "3z6awGncq9wB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_sequences = len(df_train['emb'].to_list())\n",
    "batch_size = 3\n",
    "batches_per_epoch =  4571\n",
    "assert batch_size * batches_per_epoch == num_sequences\n",
    "num_features= 768\n",
    "def train_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ],
   "outputs": [],
   "metadata": {
    "id": "5vAf9GmGlSnm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "batch_size_val = 11\n",
    "batches_per_epoch_val = 187\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "def val_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ],
   "outputs": [],
   "metadata": {
    "id": "ezFSiXl_meEo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Final Model: Training"
   ],
   "metadata": {
    "id": "jVw-FcrrjEMW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ],
   "outputs": [],
   "metadata": {
    "id": "FsT12SSbmzAl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit_generator(train_generator(df_train), steps_per_epoch=batches_per_epoch, epochs=10,\n",
    "                    validation_data=val_generator(df_val), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "4571/4571 [==============================] - 61s 13ms/step - loss: 0.3352 - acc: 0.9113 - val_loss: 0.3816 - val_acc: 0.8979\n",
      "Epoch 2/10\n",
      "4571/4571 [==============================] - 60s 13ms/step - loss: 0.3059 - acc: 0.9150 - val_loss: 0.3866 - val_acc: 0.8906\n",
      "Epoch 3/10\n",
      "4571/4571 [==============================] - 61s 13ms/step - loss: 0.2946 - acc: 0.9184 - val_loss: 0.3774 - val_acc: 0.8960\n",
      "Epoch 4/10\n",
      "4571/4571 [==============================] - 59s 13ms/step - loss: 0.2865 - acc: 0.9189 - val_loss: 0.3817 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "Epoch 5/10\n",
      "4571/4571 [==============================] - 60s 13ms/step - loss: 0.2805 - acc: 0.9202 - val_loss: 0.3752 - val_acc: 0.8979\n",
      "Epoch 6/10\n",
      "4571/4571 [==============================] - 60s 13ms/step - loss: 0.2748 - acc: 0.9210 - val_loss: 0.3730 - val_acc: 0.8960\n",
      "Epoch 7/10\n",
      "4571/4571 [==============================] - 59s 13ms/step - loss: 0.2720 - acc: 0.9215 - val_loss: 0.3716 - val_acc: 0.8989\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "Epoch 8/10\n",
      "4571/4571 [==============================] - 58s 13ms/step - loss: 0.2631 - acc: 0.9239 - val_loss: 0.3827 - val_acc: 0.8921\n",
      "Epoch 9/10\n",
      "4571/4571 [==============================] - 60s 13ms/step - loss: 0.2600 - acc: 0.9240 - val_loss: 0.3802 - val_acc: 0.9003\n",
      "Epoch 10/10\n",
      "4571/4571 [==============================] - 60s 13ms/step - loss: 0.2549 - acc: 0.9255 - val_loss: 0.3920 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f51d98d68>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 84
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "bDysNyfIm7Em",
    "outputId": "8b4e9e52-ff19-44a7-b2dc-e7a2bafd681f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Final Model: Evaluation\n",
    "\n"
   ],
   "metadata": {
    "id": "6h_RWqTXjMZX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_sequences_val = len(df_test['emb'].to_list())\n",
    "batch_size_val = 4\n",
    "batches_per_epoch_val = 343\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "model.evaluate_generator(val_generator(df_test), steps= batches_per_epoch_val)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.41612950315069047, 0.8731778425655977]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 85
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UfXOHliiNzDT",
    "outputId": "b88421b2-936a-45cc-c472-23d0154a16fa"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "bert_clasifier.ipynb\"",
   "provenance": []
  },
  "interpreter": {
   "hash": "a524880a5bb876edaae9b7b15baff302663c5354b3341491bbd2f8257d44506d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('torchtext': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}